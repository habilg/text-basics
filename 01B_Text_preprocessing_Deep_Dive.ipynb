{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxu3SZwFrr3QKt1knxqyZp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habilg/text-basics/blob/master/01B_Text_preprocessing_Deep_Dive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I9rG7dyU-1GM"
      },
      "outputs": [],
      "source": [
        "text=\"متن‌کاوي، به داده‌کاوی‌ای که بر روی متن ها انجام شود اشااررررره دارد. همچنین به عنوان آنالیز متن نیز شناخته می‌شود که منظور از آن فرایندها استخراج مکرر اطلاعات با کیفیت از متن است. اطلاعات پر کیفیت، به‌طور معمول از فهم الگوها و گرایش‌ها از طریق معانی و به وسیلهٔ یادگیری الگوهای آماری حاصل می‌شود. متن کاوی معمولاً درگیر در فرایند ساختاردهی به ورودی‌های متنی (معمولاً تجزیه، همراه با افزودن برخی ویژگی‌ها تفاسیر زبانی و حذف موارد اضافی و درج موارد بعدی در پایگاه داده انجام می‌گیرد)، استخراج الگوهای درون داده‌های ساختار یافته، و در نهایت ارزیابی و تفسیر خروجی‌ها است. «پر کیفیت» در متن کاوی معمولاً به ترکیبی از مرتبط بودن، نو ظهور بودن و جالب بودن اشاره دارد. وظایف متن کاوی معمول شامل دسته‌بندی متون، خوشه بندی متون، استخراج معنی و مفهوم، تولید رده‌بندی دانه‌ای، تجزیه و تحلیل احساسات، خلاصه کردن اسناد و مدلسازی ارتباط موجودیت‌ها است. (بطور مثال یادگیری ارتباط بین موجودیتها) آنالیز متن درگیر در بازیابی اطلاعات، آنالیز لغوی برای مطالعه توزیع فرکانس لغات، شناخت الگو، برچسب گذاری/حاشیه نویسی، استخراج اطلاعات، تکنیک‌های داده کاوی شامل آنالیز اتصال و ارتباط، بصری سازی، و آنالیز پیشگویانه است. هدف نهایی، اساساً تبدیل متن به داده برای آنالیز از طریق کاربرد پردازش زبان‌های طبیعی و متدهای تحلیلی است. یک کاربرد معمول، جهت اسکن مجموعه‌ای از اسناد نوشته شده در یک زبان طبیعی و مدل کردن مجموعه اسناد برای اهداف کلاس‌بندی پیشگویانه یا پرکردن یک پایگاه داده یا ایندکس جستجو با اطلاعات استخراج شده‌است\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hazm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "5qUB591HYYJq",
        "outputId": "398b2c54-1487-46c0-aea7-35c23b87cd1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.9.0-py3-none-any.whl (477 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m477.8/477.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (4.3.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (3.8.1)\n",
            "Collecting numpy<2.0.0,>=1.24.3 (from hazm)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite<0.10.0,>=0.9.9 (from hazm)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (6.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.65.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.1.0)\n",
            "Installing collected packages: python-crfsuite, numpy, hazm\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed hazm-0.9.0 numpy-1.24.3 python-crfsuite-0.9.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.22.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "rglVVkNBl67i",
        "outputId": "402a8a17-c16f-40e4-b31f-9e089e28c35c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.22.4\n",
            "  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "hazm 0.9.0 requires numpy<2.0.0,>=1.24.3, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.22.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/roshan-research/hazm\n",
        "\n",
        "\n",
        "from hazm import Normalizer,Stemmer,Lemmatizer,POSTagger,Chunker,DependencyParser"
      ],
      "metadata": {
        "id": "_BAxc-suYaFs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer=Normalizer()\n",
        "text = normalizer.normalize(text).replace(\"\\u200c\",\" \")\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "YdcsM9V-ZOFs",
        "outputId": "92a5459e-0542-4d04-f859-b713c7ca6d0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'متن کاوی، به داده کاوی ای که بر روی متن ها انجام شود اشاارره دارد. همچنین به عنوان آنالیز متن نیز شناخته می شود که منظور از آن فرایندها استخراج مکرر اطلاعات با کیفیت از متن است. اطلاعات پر کیفیت، به طور معمول از فهم الگوها و گرایش ها از طریق معانی و به وسیله یادگیری الگوهای آماری حاصل می شود. متن کاوی معمولا درگیر در فرایند ساختاردهی به ورودی های متنی (معمولا تجزیه، همراه با افزودن برخی ویژگی ها تفاسیر زبانی و حذف موارد اضافی و درج موارد بعدی در پایگاه داده انجام می گیرد)، استخراج الگوهای درون داده های ساختار یافته، و در نهایت ارزیابی و تفسیر خروجی ها است. «پر کیفیت» در متن کاوی معمولا به ترکیبی از مرتبط بودن، نو ظهور بودن و جالب بودن اشاره دارد. وظایف متن کاوی معمول شامل دسته بندی متون، خوشه بندی متون، استخراج معنی و مفهوم، تولید رده بندی دانه ای، تجزیه و تحلیل احساسات، خلاصه کردن اسناد و مدلسازی ارتباط موجودیت ها است. (بطور مثال یادگیری ارتباط بین موجودیتها) آنالیز متن درگیر در بازیابی اطلاعات، آنالیز لغوی برای مطالعه توزیع فرکانس لغات، شناخت الگو، برچسب گذاری / حاشیه نویسی، استخراج اطلاعات، تکنیک های داده کاوی شامل آنالیز اتصال و ارتباط، بصری سازی، و آنالیز پیشگویانه است. هدف نهایی، اساسا تبدیل متن به داده برای آنالیز از طریق کاربرد پردازش زبان های طبیعی و متدهای تحلیلی است. یک کاربرد معمول، جهت اسکن مجموعه ای از اسناد نوشته شده در یک زبان طبیعی و مدل کردن مجموعه اسناد برای اهداف کلاس بندی پیشگویانه یا پرکردن یک پایگاه داده یا ایندکس جستجو با اطلاعات استخراج شده است'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import itertools\n",
        "import operator"
      ],
      "metadata": {
        "id": "KA0f15DTaZuK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''.join(ch for ch, _ in itertools.groupby(text))\n",
        "text.strip()\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "ZY786fZ_Z12d",
        "outputId": "aaf56a1e-2229-4c56-d755-f95f2d810cff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'متن کاوی، به داده کاوی ای که بر روی متن ها انجام شود اشاره دارد. همچنین به عنوان آنالیز متن نیز شناخته می شود که منظور از آن فرایندها استخراج مکر اطلاعات با کیفیت از متن است. اطلاعات پر کیفیت، به طور معمول از فهم الگوها و گرایش ها از طریق معانی و به وسیله یادگیری الگوهای آماری حاصل می شود. متن کاوی معمولا درگیر در فرایند ساختاردهی به ورودی های متنی (معمولا تجزیه، همراه با افزودن برخی ویژگی ها تفاسیر زبانی و حذف موارد اضافی و درج موارد بعدی در پایگاه داده انجام می گیرد)، استخراج الگوهای درون داده های ساختار یافته، و در نهایت ارزیابی و تفسیر خروجی ها است. «پر کیفیت» در متن کاوی معمولا به ترکیبی از مرتبط بودن، نو ظهور بودن و جالب بودن اشاره دارد. وظایف متن کاوی معمول شامل دسته بندی متون، خوشه بندی متون، استخراج معنی و مفهوم، تولید رده بندی دانه ای، تجزیه و تحلیل احساسات، خلاصه کردن اسناد و مدلسازی ارتباط موجودیت ها است. (بطور مثال یادگیری ارتباط بین موجودیتها) آنالیز متن درگیر در بازیابی اطلاعات، آنالیز لغوی برای مطالعه توزیع فرکانس لغات، شناخت الگو، برچسب گذاری / حاشیه نویسی، استخراج اطلاعات، تکنیک های داده کاوی شامل آنالیز اتصال و ارتباط، بصری سازی، و آنالیز پیشگویانه است. هدف نهای، اساسا تبدیل متن به داده برای آنالیز از طریق کاربرد پردازش زبان های طبیعی و متدهای تحلیلی است. یک کاربرد معمول، جهت اسکن مجموعه ای از اسناد نوشته شده در یک زبان طبیعی و مدل کردن مجموعه اسناد برای اهداف کلاس بندی پیشگویانه یا پرکردن یک پایگاه داده یا ایندکس جستجو با اطلاعات استخراج شده است'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BWksLtaamUVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop word Challang:  \n",
        "+ should they removed in all situations?\n",
        "+ "
      ],
      "metadata": {
        "id": "pwRAgqI0m3MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Stopword = ['همچنان', 'مدت', 'چیز', 'سایر', 'جا', 'طی', 'کل', 'کنونی', 'بیرون','های', 'مثلا', 'کامل','ها', 'کاملا','گیرد','شود','است', 'آنکه', \n",
        "            'موارد', 'واقعی', 'امور', 'اکنون', 'بطور', 'بخشی', 'تحت', 'چگونه', 'عدم', 'نوعی', 'حاضر', 'وضع', 'مقابل', 'کنار', 'خویش', 'نگاه', 'درون',\n",
        "            'زمانی', 'بنابراین', 'تو', 'خیلی', 'بزرگ', 'خودش', 'جز', 'اینجا', 'مختلف', 'توسط', 'نوع', 'همچنین', 'آنجا', 'قبل', 'جناح', 'اینها', 'طور', 'شاید',\n",
        "            'ایشان', 'جهت', 'طریق', 'مانند', 'پیدا', 'ممکن', 'کسانی', 'جای', 'کسی', 'غیر', 'بی', 'قابل', 'درباره', 'جدید', 'وقتی', 'اخیر', 'چرا', 'بیش',\n",
        "            'روی', 'طرف', 'جریان', 'زیر', 'آنچه', 'البته', 'فقط', 'چیزی', 'چون', 'برابر', 'هنوز', 'بخش', 'زمینه', 'بین', 'بدون', 'استفاد', 'همان', 'نشان',\n",
        "            'بسیاری', 'بعد', 'عمل', 'روز', 'اعلام', 'چند', 'آنان', 'بلکه', 'امروز', 'تمام', 'بیشتر', 'آیا', 'برخی', 'علیه', 'دیگری', 'ویژه', 'گذشته', 'انجام',\n",
        "            'حتی', 'داده', 'راه', 'سوی', 'ولی', 'زمان', 'حال', 'تنها', 'بسیار', 'یعنی', 'عنوان', 'همین', 'هبچ', 'پیش', 'وی', 'یکی', 'اینکه', 'وجود'\n",
        "            , 'شما', 'پس', 'چنین', 'میان', 'مورد', 'چه', 'اگر', 'همه', 'نه', 'دیگر', 'آنها', 'باید', 'هر', 'او', 'ما', 'من', 'تا', 'نیز', 'اما', \n",
        "            'یک', 'خود', 'بر', 'یا', 'هم','ای', 'را','دارد', 'این',\"می\", 'با','دارد','،',',','.', 'آن', 'برای', 'و', 'در', 'به', 'که', 'از']"
      ],
      "metadata": {
        "id": "_2xZBq1AlRJ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}