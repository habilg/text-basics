{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OKy8jEAX18MS60P9loSwNMQqVnMyIeO2",
      "authorship_tag": "ABX9TyPx6VRpflfFk0SQfnl1bGqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habilg/text-basics/blob/master/02A_word_representation(embedding)_high_level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word representation(embedding)\n",
        "\n",
        "This a way to describe every word with features to find their anology. it is not a matter this describing features are meaningfull for human. \n",
        "There are some methods to achieve it. But generally two main aproachs are:\n",
        "\n",
        "\n",
        "> static embeding  \n",
        "> dynamic embeding\n",
        "\n",
        "maybe you think if we collect all the world words in a very huge corpus, we could find the unique final vector for every vocabulary.In fact, it is not the case, since words relationship are specific for every context, so we expect that same word embeding vector become diffrent from one context to another context.\n",
        "\n",
        "static embedings are representation of words which obtained from a very large corpus. like fasttext, GloVe. However, dynamic representation is obtained form the text.\n",
        "\n",
        "## What is Keras soloution?\n",
        "it provides an `embedding layer`, which is trainable. It means that this layer could initilized with static weights or it could find proper weights during the trainig. \n",
        "input for this layer must be a type of `tf.keras.layers.TextVectorization, tf.keras.layers.StringLookup, or tf.keras.layers.IntegerLookup`."
      ],
      "metadata": {
        "id": "yaAL00n6nveK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gDCjFb_1nYJK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding,TextVectorization\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using pretrained weights-GloVe:\n",
        "\n",
        "embedding_initializer argument must be initialized by a embedding matrix of the training words"
      ],
      "metadata": {
        "id": "etH38B9dCMr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "  \"I write, erase, rewrite\",\n",
        "  \"Erase again, and then\",\n",
        "  \"A poppy blooms.\",\n",
        "]"
      ],
      "metadata": {
        "id": "GCYEdy39Eb1N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "text_vectorization = TextVectorization(output_mode=\"int\")\n",
        "text_vectorization.adapt(dataset)\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))"
      ],
      "metadata": {
        "id": "qPN_Ck8xFcG4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens=100\n",
        "word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x778DH7hGzI5",
        "outputId": "8d5a748d-4fed-4de3-97ee-d7ff70b4ad78"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '[UNK]': 1,\n",
              " 'erase': 2,\n",
              " 'write': 3,\n",
              " 'then': 4,\n",
              " 'rewrite': 5,\n",
              " 'poppy': 6,\n",
              " 'i': 7,\n",
              " 'blooms': 8,\n",
              " 'and': 9,\n",
              " 'again': 10,\n",
              " 'a': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_for_vocab(filepath, word_index,embedding_dim):\n",
        "    vocab_size = len(word_index) + 1\n",
        "      \n",
        "    # Adding again 1 because of reserved 0 index\n",
        "    embedding_matrix_vocab = np.zeros((vocab_size,embedding_dim))\n",
        "  \n",
        "    with open(filepath, encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            word, vector = line.split(maxsplit=1)\n",
        "            if word in word_index:\n",
        "                idx = word_index[word]\n",
        "                embedding_matrix_vocab[idx] = np.fromstring(vector, \"f\", sep=\" \")\n",
        "  \n",
        "    return embedding_matrix_vocab"
      ],
      "metadata": {
        "id": "_lc99xBHTiOE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix for vocab: word_index\n",
        "embedding_dim = 50\n",
        "embedding_matrix= embedding_for_vocab('/content/drive/MyDrive/glove.6B.50d.txt',\n",
        "                                             word_index,\n",
        "                                             embedding_dim)\n",
        "  \n",
        "print(\"Dense vector for first word is => \", embedding_matrix[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P5YJbmHbChe",
        "outputId": "4c5e1459-217a-4a80-8c3f-212ac14e6421"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense vector for first word is =>  [-0.14342999 -0.21572     0.95021999 -0.060348   -0.19272     0.59243\n",
            "  0.22474     0.34395999 -0.19253001  0.41418999 -0.60180998  0.15369999\n",
            " -0.41172999 -0.46133     0.34940001  0.56075001 -0.16425    -1.12510002\n",
            "  0.95339     0.058167   -0.47325    -0.55941999  0.018379   -0.81616998\n",
            "  0.28639001 -0.80637002 -0.91731     0.012369    1.03820002 -0.80427003\n",
            "  1.00250006  0.59998    -0.30706999 -0.27456999 -0.54820001  0.48576\n",
            " -0.44499999 -0.16799     0.67354    -1.19289994 -0.29357001 -0.69257998\n",
            "  0.025876    0.27287999 -0.26589     0.78315002  0.5589      0.60016\n",
            "  0.16568001 -0.90461999]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")"
      ],
      "metadata": {
        "id": "zYw5Z2-NCLGP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make trainable a pretrained initializer"
      ],
      "metadata": {
        "id": "a9LoEwx4KxEN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XXN2c73VJNpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FV_UM4oOLUW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SR7RxwvHLUUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1KyERykKLUQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpvfhf4YLUMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Layer from the ground."
      ],
      "metadata": {
        "id": "QwcW4jJ_LU9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "\n",
        "voc_size=100\n",
        "onehot_repr=[one_hot(words,voc_size)for words in dataset]\n",
        "onehot_repr"
      ],
      "metadata": {
        "id": "MqImNYsBLoae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length=8\n",
        "encoded_sentences=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "encoded_sentences"
      ],
      "metadata": {
        "id": "qy2bPctKPRQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "embedding_dim=10\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_dim,input_length=sent_length,mask_zero=True))\n",
        "model.compile('adam','mse')"
      ],
      "metadata": {
        "id": "N2ks2aZFPnEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "RkTJSh9LP-uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_sentences[0])\n",
        "print(model.predict(encoded_sentences[0]))"
      ],
      "metadata": {
        "id": "E7r_cK_AQFrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_sentences[0])\n",
        "print(model.predict(encoded_sentences[0]))"
      ],
      "metadata": {
        "id": "qXHpYM-RQopN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XVYNqSAkR91e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}