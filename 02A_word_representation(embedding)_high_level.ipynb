{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OKy8jEAX18MS60P9loSwNMQqVnMyIeO2",
      "authorship_tag": "ABX9TyMK8a57OXGVOmmEpv9/p+Ah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habilg/text-basics/blob/master/02A_word_representation(embedding)_high_level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word representation(embedding)\n",
        "\n",
        "This a way to describe every word with features to find their anology. it is not a matter this describing features are meaningfull for human. \n",
        "There are some methods to achieve it. But generally two main aproachs are:\n",
        "\n",
        "\n",
        "> static embeding  \n",
        "> dynamic embeding\n",
        "\n",
        "maybe you think if we collect all the world words in a very huge corpus, we could find the unique final vector for every vocabulary.In fact, it is not the case, since words relationship are specific for every context, so we expect that same word embeding vector become diffrent from one context to another context.\n",
        "\n",
        "static embedings are representation of words which obtained from a very large corpus. like fasttext, GloVe. However, dynamic representation is obtained form the text.\n",
        "\n",
        "## What is Keras soloution?\n",
        "it provides an `embedding layer`, which is trainable. It means that this layer could initilized with static weights or it could find proper weights during the trainig. \n",
        "input for this layer must be a type of `tf.keras.layers.TextVectorization, tf.keras.layers.StringLookup, or tf.keras.layers.IntegerLookup`."
      ],
      "metadata": {
        "id": "yaAL00n6nveK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gDCjFb_1nYJK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e=Embedding()"
      ],
      "metadata": {
        "id": "sUBe2TYn0Att"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using pretrained weights-GloVe:\n",
        "\n",
        "embedding_initializer argument must be initialized by a embedding matrix of the training words"
      ],
      "metadata": {
        "id": "etH38B9dCMr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "  \"I write, erase, rewrite\",\n",
        "  \"Erase again, and then\",\n",
        "  \"A poppy blooms.\",\n",
        "]"
      ],
      "metadata": {
        "id": "GCYEdy39Eb1N"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "embedding_dim=50 #based on using the glove.6B.50d.txt\n",
        "embeddings_index = {}\n",
        "with open('/content/drive/MyDrive/glove.6B.50d.txt') as f:\n",
        "  for line in f:\n",
        "    word, coefs = line.split(maxsplit=1)\n",
        "    coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "    embeddings_index[word] = coefs\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdg__j7MEzMm",
        "outputId": "f0d5f1fb-99b9-4861-ecaf-eb9f68137a12"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(embeddings_index.items())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pDZi7b-JrPI",
        "outputId": "8d17203d-c700-410d-bf9d-ec21fca8ba98"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the',\n",
              " array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
              "        -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
              "         2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
              "         1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
              "        -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
              "        -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
              "         4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
              "         7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
              "        -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
              "         1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# producing embedding_matrix\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "text_vectorization = TextVectorization(output_mode=\"int\")\n",
        "text_vectorization.adapt(dataset)\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))"
      ],
      "metadata": {
        "id": "qPN_Ck8xFcG4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x778DH7hGzI5",
        "outputId": "78854fdb-95c6-4490-8536-a8ed85783e00"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '[UNK]': 1,\n",
              " 'erase': 2,\n",
              " 'write': 3,\n",
              " 'then': 4,\n",
              " 'rewrite': 5,\n",
              " 'poppy': 6,\n",
              " 'i': 7,\n",
              " 'blooms': 8,\n",
              " 'and': 9,\n",
              " 'again': 10,\n",
              " 'a': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens=len(word_index)\n",
        "max_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC8K1z1jIEEA",
        "outputId": "f7dde51c-2095-4531-ae7d-6002edb20f2e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i < max_tokens:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_matrix[2] #embeding vector for word 'erase'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOCdqwibG8mt",
        "outputId": "c9fcd030-ef89-48f1-8d63-932af115d09c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.14342999, -0.21572   ,  0.95021999, -0.060348  , -0.19272   ,\n",
              "        0.59243   ,  0.22474   ,  0.34395999, -0.19253001,  0.41418999,\n",
              "       -0.60180998,  0.15369999, -0.41172999, -0.46133   ,  0.34940001,\n",
              "        0.56075001, -0.16425   , -1.12510002,  0.95339   ,  0.058167  ,\n",
              "       -0.47325   , -0.55941999,  0.018379  , -0.81616998,  0.28639001,\n",
              "       -0.80637002, -0.91731   ,  0.012369  ,  1.03820002, -0.80427003,\n",
              "        1.00250006,  0.59998   , -0.30706999, -0.27456999, -0.54820001,\n",
              "        0.48576   , -0.44499999, -0.16799   ,  0.67354   , -1.19289994,\n",
              "       -0.29357001, -0.69257998,  0.025876  ,  0.27287999, -0.26589   ,\n",
              "        0.78315002,  0.5589    ,  0.60016   ,  0.16568001, -0.90461999])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")"
      ],
      "metadata": {
        "id": "zYw5Z2-NCLGP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make trainable a pretrained initializer"
      ],
      "metadata": {
        "id": "a9LoEwx4KxEN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XXN2c73VJNpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FV_UM4oOLUW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SR7RxwvHLUUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1KyERykKLUQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpvfhf4YLUMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Layer from the ground."
      ],
      "metadata": {
        "id": "QwcW4jJ_LU9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "\n",
        "voc_size=100\n",
        "onehot_repr=[one_hot(words,voc_size)for words in dataset]\n",
        "onehot_repr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqImNYsBLoae",
        "outputId": "990f7cb7-1e62-4736-83f8-52bec04436f4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[22, 74, 29, 3], [29, 20, 38, 87], [75, 83, 49]]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length=8\n",
        "encoded_sentences=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "encoded_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy2bPctKPRQe",
        "outputId": "cb32118e-bf63-4973-8c96-910369723075"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0, 22, 74, 29,  3],\n",
              "       [ 0,  0,  0,  0, 29, 20, 38, 87],\n",
              "       [ 0,  0,  0,  0,  0, 75, 83, 49]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "embedding_dim=10\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_dim,input_length=sent_length,mask_zero=True))\n",
        "model.compile('adam','mse')"
      ],
      "metadata": {
        "id": "N2ks2aZFPnEG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkTJSh9LP-uU",
        "outputId": "c180d8b6-6a0d-4d61-967e-afdf19c8f928"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 8, 10)             1000      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,000\n",
            "Trainable params: 1,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_sentences[0])\n",
        "print(model.predict(encoded_sentences[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7r_cK_AQFrH",
        "outputId": "f65385e4-67a7-469c-ac4a-7d605533ced7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0 22 74 29  3]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[-0.00569334  0.00257286  0.03579393  0.03102187 -0.02277086 -0.02277479\n",
            "  -0.00182947  0.01928984 -0.0045648  -0.04526095]\n",
            " [-0.00569334  0.00257286  0.03579393  0.03102187 -0.02277086 -0.02277479\n",
            "  -0.00182947  0.01928984 -0.0045648  -0.04526095]\n",
            " [-0.00569334  0.00257286  0.03579393  0.03102187 -0.02277086 -0.02277479\n",
            "  -0.00182947  0.01928984 -0.0045648  -0.04526095]\n",
            " [-0.00569334  0.00257286  0.03579393  0.03102187 -0.02277086 -0.02277479\n",
            "  -0.00182947  0.01928984 -0.0045648  -0.04526095]\n",
            " [ 0.04262597  0.03559327  0.02676548 -0.01363174 -0.03188284  0.04452128\n",
            "   0.00305692  0.02038933  0.04472685 -0.04297394]\n",
            " [-0.02634639  0.0303622   0.0400802   0.01257122  0.02991608 -0.02740448\n",
            "  -0.02059689 -0.00821769 -0.02704332  0.01997993]\n",
            " [-0.01714382  0.04435327  0.01093065 -0.03152341  0.00158608  0.00651101\n",
            "  -0.00473733 -0.02673093  0.00446523  0.04212156]\n",
            " [ 0.04971078 -0.01255681  0.04776806 -0.02296456 -0.048112    0.04334671\n",
            "  -0.00024748 -0.03971709 -0.00592555  0.03721717]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_sentences[0])\n",
        "print(model.predict(encoded_sentences[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXHpYM-RQopN",
        "outputId": "12d83ee5-72f5-416c-d618-e946a928c5b6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0 22 74 29  3]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "[[-0.00569334  0.00257286  0.03579393  0.03102187 -0.02277086 -0.02277479\n",
            "  -0.00182947  0.01928984 -0.0045648  -0.04526095]\n",
            " [-0.00569334  0.00257286  0.03579393  0.03102187 -0.02277086 -0.02277479\n",
            "  -0.00182947  0.01928984 -0.0045648  -0.04526095]\n",
            " [-0.00569334  0.00257286  0.03579393  0.03102187 -0.02277086 -0.02277479\n",
            "  -0.00182947  0.01928984 -0.0045648  -0.04526095]\n",
            " [-0.00569334  0.00257286  0.03579393  0.03102187 -0.02277086 -0.02277479\n",
            "  -0.00182947  0.01928984 -0.0045648  -0.04526095]\n",
            " [ 0.04262597  0.03559327  0.02676548 -0.01363174 -0.03188284  0.04452128\n",
            "   0.00305692  0.02038933  0.04472685 -0.04297394]\n",
            " [-0.02634639  0.0303622   0.0400802   0.01257122  0.02991608 -0.02740448\n",
            "  -0.02059689 -0.00821769 -0.02704332  0.01997993]\n",
            " [-0.01714382  0.04435327  0.01093065 -0.03152341  0.00158608  0.00651101\n",
            "  -0.00473733 -0.02673093  0.00446523  0.04212156]\n",
            " [ 0.04971078 -0.01255681  0.04776806 -0.02296456 -0.048112    0.04334671\n",
            "  -0.00024748 -0.03971709 -0.00592555  0.03721717]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XVYNqSAkR91e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}